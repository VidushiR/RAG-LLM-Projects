{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2a94494-f75b-4a1c-9994-246c5f48974d",
   "metadata": {},
   "source": [
    "# Embeddings and Vector Store (AskMyDocs RAG)\n",
    "\n",
    "## Goal\n",
    "Convert chunked corpus into embeddings and build a vector index for semantic retrieval.\n",
    "\n",
    "### Inputs\n",
    "- data/processed/arxiv_chunks_*.csv\n",
    "\n",
    "### Outputs\n",
    "- Vector index (FAISS)\n",
    "- Metadata mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "527ef57d-f410-464b-b43c-109e97ef3be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run once per environment (then comment this out)\n",
    "!pip -q install torch sentence-transformers faiss-cpu pandas pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c1ad145-a210-44cf-9255-4dc79edf733a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: C:\\Users\\vidus\\Projects\\RAG-LLM-Projects\\AskMyDocs-RAG-Chatbot\n",
      "Processed dir: C:\\Users\\vidus\\Projects\\RAG-LLM-Projects\\AskMyDocs-RAG-Chatbot\\data\\processed\n",
      "Torch: 2.8.0+cpu\n"
     ]
    }
   ],
   "source": [
    "#import and install modules\n",
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Keep notebook output clean\n",
    "logging.getLogger(\"huggingface_hub\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"sentence_transformers\").setLevel(logging.ERROR)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "PROCESSED_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "\n",
    "print(\"Project root:\", PROJECT_ROOT)\n",
    "print(\"Processed dir:\", PROCESSED_DIR)\n",
    "print(\"Torch:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a19ebb9-a804-4f63-848e-0646acd56a61",
   "metadata": {},
   "source": [
    "### Load latest file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74d7923e-6a51-45f5-90ab-6829b0db10a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: arxiv_chunks_20260223_1021.csv\n",
      "Rows: 136\n",
      "Chunks: 136\n"
     ]
    }
   ],
   "source": [
    "chunk_files = sorted(PROCESSED_DIR.glob(\"arxiv_chunks_*.csv\"))\n",
    "assert chunk_files, f\"No chunk files found in {PROCESSED_DIR}\"\n",
    "\n",
    "CHUNKS_FILE = chunk_files[-1]  # most recent\n",
    "df_chunks = pd.read_csv(CHUNKS_FILE)\n",
    "\n",
    "# Required column check\n",
    "assert \"chunk_text\" in df_chunks.columns, \"Expected column 'chunk_text' not found\"\n",
    "\n",
    "texts = df_chunks[\"chunk_text\"].astype(str).tolist()\n",
    "\n",
    "print(\"Using:\", CHUNKS_FILE.name)\n",
    "print(\"Rows:\", len(df_chunks))\n",
    "print(\"Chunks:\", len(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108bed49-4dea-4a52-96c9-d445a9ccc530",
   "metadata": {},
   "source": [
    "### Load embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70c05148-ec76-4609-ab41-0e2e44559c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3990a3e44ac844d19cb871792a1f4094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded ✅\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "print(\"Model loaded ✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de50103-f36b-4ec6-93aa-fcb9bdcd67ff",
   "metadata": {},
   "source": [
    "### Create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b7c8287-3dc6-44d2-9ca3-9d91b5ef4b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (136, 384)\n"
     ]
    }
   ],
   "source": [
    "embeddings = model.encode(\n",
    "    texts,\n",
    "    convert_to_numpy=True,\n",
    "    show_progress_bar=False\n",
    ").astype(\"float32\")\n",
    "\n",
    "print(\"Embeddings shape:\", embeddings.shape)  # (n_chunks, 384)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a6190f-e9d0-4086-b420-600b448cbb1d",
   "metadata": {},
   "source": [
    "### Build FAISS index (cosine similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca0ac1e0-414d-41c1-a3aa-eac2559eec33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index size: 136\n",
      "FAISS dim: 384\n"
     ]
    }
   ],
   "source": [
    "# Cosine similarity via normalized vectors + inner product\n",
    "faiss.normalize_L2(embeddings)\n",
    "\n",
    "dim = embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(dim)\n",
    "index.add(embeddings)\n",
    "\n",
    "print(\"FAISS index size:\", index.ntotal)\n",
    "print(\"FAISS dim:\", dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da33720b-65e2-458c-bfc5-b68d4a7437ac",
   "metadata": {},
   "source": [
    "### Save FAISS + metadata mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4087f50-f510-4dd3-928e-9bc9c3b7dc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved index: C:\\Users\\vidus\\Projects\\RAG-LLM-Projects\\AskMyDocs-RAG-Chatbot\\data\\processed\\faiss\\arxiv_faiss.index\n",
      "Saved metadata: C:\\Users\\vidus\\Projects\\RAG-LLM-Projects\\AskMyDocs-RAG-Chatbot\\data\\processed\\faiss\\arxiv_chunks_meta.parquet\n",
      "Metadata columns: ['chunk_id', 'doc_id', 'chunk_index', 'title', 'categories', 'update_date', 'chunk_text']\n"
     ]
    }
   ],
   "source": [
    "OUT_DIR = PROCESSED_DIR / \"faiss\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "INDEX_PATH = OUT_DIR / \"arxiv_faiss.index\"\n",
    "META_PATH  = OUT_DIR / \"arxiv_chunks_meta.parquet\"\n",
    "\n",
    "faiss.write_index(index, str(INDEX_PATH))\n",
    "\n",
    "# Keep metadata lightweight + useful for retrieval\n",
    "meta_cols = [c for c in [\"chunk_id\", \"doc_id\", \"chunk_index\", \"title\", \"categories\", \"update_date\", \"chunk_text\"] if c in df_chunks.columns]\n",
    "df_meta = df_chunks[meta_cols].copy()\n",
    "df_meta.to_parquet(META_PATH, index=False)\n",
    "\n",
    "print(\"Saved index:\", INDEX_PATH)\n",
    "print(\"Saved metadata:\", META_PATH)\n",
    "print(\"Metadata columns:\", meta_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4474ecc8-3097-4918-b438-6b89e8528cda",
   "metadata": {},
   "source": [
    "## Quick retrieval test (sanity check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5f65658-00eb-4d88-9256-7069c4f133d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>title</th>\n",
       "      <th>categories</th>\n",
       "      <th>update_date</th>\n",
       "      <th>chunk_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.516908</td>\n",
       "      <td>704.1028__0</td>\n",
       "      <td>704.1028</td>\n",
       "      <td>A neural network approach to ordinal regression</td>\n",
       "      <td>cs.LG cs.AI cs.NE</td>\n",
       "      <td>2007-05-23</td>\n",
       "      <td>Title: A neural network approach to ordinal re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.456485</td>\n",
       "      <td>705.1209__1</td>\n",
       "      <td>705.1209</td>\n",
       "      <td>Artificial Intelligence for Conflict Management</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>2007-05-23</td>\n",
       "      <td>neural networks. The results show that SVMs pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.410357</td>\n",
       "      <td>705.1209__0</td>\n",
       "      <td>705.1209</td>\n",
       "      <td>Artificial Intelligence for Conflict Management</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>2007-05-23</td>\n",
       "      <td>Title: Artificial Intelligence for Conflict Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.381806</td>\n",
       "      <td>705.2235__0</td>\n",
       "      <td>705.2235</td>\n",
       "      <td>Response Prediction of Structural System Subje...</td>\n",
       "      <td>cs.AI</td>\n",
       "      <td>2007-05-23</td>\n",
       "      <td>Title: Response Prediction of Structural Syste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.373325</td>\n",
       "      <td>704.1028__1</td>\n",
       "      <td>704.1028</td>\n",
       "      <td>A neural network approach to ordinal regression</td>\n",
       "      <td>cs.LG cs.AI cs.NE</td>\n",
       "      <td>2007-05-23</td>\n",
       "      <td>ges of traditional neural networks: learning i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       score     chunk_id    doc_id  \\\n",
       "16  0.516908  704.1028__0  704.1028   \n",
       "83  0.456485  705.1209__1  705.1209   \n",
       "82  0.410357  705.1209__0  705.1209   \n",
       "94  0.381806  705.2235__0  705.2235   \n",
       "17  0.373325  704.1028__1  704.1028   \n",
       "\n",
       "                                                title         categories  \\\n",
       "16    A neural network approach to ordinal regression  cs.LG cs.AI cs.NE   \n",
       "83    Artificial Intelligence for Conflict Management              cs.AI   \n",
       "82    Artificial Intelligence for Conflict Management              cs.AI   \n",
       "94  Response Prediction of Structural System Subje...              cs.AI   \n",
       "17    A neural network approach to ordinal regression  cs.LG cs.AI cs.NE   \n",
       "\n",
       "   update_date                                         chunk_text  \n",
       "16  2007-05-23  Title: A neural network approach to ordinal re...  \n",
       "83  2007-05-23  neural networks. The results show that SVMs pr...  \n",
       "82  2007-05-23  Title: Artificial Intelligence for Conflict Ma...  \n",
       "94  2007-05-23  Title: Response Prediction of Structural Syste...  \n",
       "17  2007-05-23  ges of traditional neural networks: learning i...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def search(query: str, k: int = 5) -> pd.DataFrame:\n",
    "    q = model.encode([query], convert_to_numpy=True).astype(\"float32\")\n",
    "    faiss.normalize_L2(q)\n",
    "    scores, idxs = index.search(q, k)\n",
    "\n",
    "    results = df_meta.iloc[idxs[0]].copy()\n",
    "    results[\"score\"] = scores[0]\n",
    "    \n",
    "    cols = [\"score\"] + [c for c in [\"chunk_id\", \"doc_id\", \"title\", \"categories\", \"update_date\", \"chunk_text\"] if c in results.columns]\n",
    "    return results[cols]\n",
    "\n",
    "search(\"neural network for text classification\", k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f433717-56ee-458b-88b0-85c89883ee72",
   "metadata": {},
   "source": [
    "##  Retrieval Validation Successful\n",
    "\n",
    "The FAISS vector index was successfully created and tested using a sample semantic query.  \n",
    "The system returned the top-k most relevant chunks, confirming that:\n",
    "\n",
    "- Text embeddings were generated correctly using `all-MiniLM-L6-v2`\n",
    "- Cosine similarity search is functioning as expected\n",
    "- Metadata mapping correctly links vectors back to source documents\n",
    "- Retrieved results align with the semantic meaning of the query\n",
    "\n",
    "The semantic retrieval layer is now fully operational.\n",
    "\n",
    "---\n",
    "\n",
    "##  Generated Artifacts\n",
    "\n",
    "The following reusable artifacts were saved:\n",
    "\n",
    "- `data/processed/faiss/arxiv_faiss.index` — Vector index  \n",
    "- `data/processed/faiss/arxiv_chunks_meta.parquet` — Metadata mapping  \n",
    "\n",
    "These files allow semantic search without recomputing embeddings.\n",
    "\n",
    "---\n",
    "\n",
    "##  Next Step: RAG Inference Pipeline\n",
    "\n",
    "The next stage will implement the Retrieval-Augmented Generation workflow:\n",
    "\n",
    "1. Load the saved FAISS index  \n",
    "2. Load metadata mapping  \n",
    "3. Retrieve top-k relevant chunks for a user query  \n",
    "4. Construct a context-aware prompt  \n",
    "5. Generate a grounded answer using an LLM  \n",
    "6. Return the answer with source citations  \n",
    "\n",
    "---\n",
    "\n",
    "This notebook completes the **Vector Store Construction Layer** of the AskMyDocs RAG system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e819ca7-e01a-4cb7-adb8-3e3ac502b52c",
   "metadata": {},
   "source": [
    "## Why the Vector Store Construction Layer Is Important\n",
    "\n",
    "The Vector Store Construction Layer is the foundation of the Retrieval-Augmented Generation (RAG) pipeline. It transforms raw text documents into searchable semantic representations, enabling accurate and efficient retrieval.\n",
    "\n",
    "### Key Reasons\n",
    "\n",
    "- **Enables Semantic Search**  \n",
    "  Converts text into embeddings, allowing the system to retrieve results based on meaning rather than exact keyword matches.\n",
    "\n",
    "- **Prevents Hallucinations**  \n",
    "  Retrieved context grounds the LLM’s responses in real documents, reducing incorrect or fabricated answers.\n",
    "\n",
    "- **Improves Accuracy and Relevance**  \n",
    "  Cosine similarity search ensures that the most semantically related chunks are selected for answering a query.\n",
    "\n",
    "- **Supports Scalability**  \n",
    "  FAISS enables fast similarity search across thousands or millions of vectors, making the system production-ready.\n",
    "\n",
    "- **Promotes Modular Architecture**  \n",
    "  Separates retrieval from generation, allowing independent upgrades to embedding models, vector databases, or LLMs.\n",
    "\n",
    "- **Enables Reusability**  \n",
    "  Once built, the saved FAISS index and metadata mapping can be reused without recomputing embeddings.\n",
    "\n",
    "---\n",
    "\n",
    "In summary, the Vector Store Construction Layer converts static documents into a dynamic, searchable knowledge base that powers the entire RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3e57b2-9859-4313-9850-1a1d8e0244a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
